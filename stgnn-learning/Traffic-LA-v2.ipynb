{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78347376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duhaolei/my-pytorch-project/torch_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Here we import database we will need later\n",
    "import torch    # Basic PyTorch library for tensor operations\n",
    "import torch.nn as nn   # Building Neural Networks\n",
    "import torch.nn.functional as F # Activation functions and other utilities\n",
    "from torch_geometric_temporal.nn.recurrent import A3TGCN    # See below\n",
    "from torch_geometric_temporal.dataset import METRLADatasetLoader    # Load the dataset\n",
    "from torch_geometric.loader import DataLoader  # For batching and loading data\n",
    "from tqdm import tqdm   # The visualization of processing progress\n",
    "import matplotlib.pyplot as plt # For basic visualization\n",
    "import seaborn as sns  # For advanced visualization\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation and analysis that i am familiar with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971a9877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[207, 2, 12], edge_index=[2, 1722], edge_attr=[1722], y=[207, 12])\n"
     ]
    }
   ],
   "source": [
    "# Now, we will load the METR-LA dataset and see what is inside\n",
    "loader = METRLADatasetLoader()\n",
    "# We will take the data from the time span of before 60 min to after 60 min\n",
    "dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
    "\n",
    "# Take a look at the data structure -- \n",
    "for snapshot in dataset:\n",
    "    print(snapshot)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2343b53",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "#### Here we will config a simple GNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77f4137",
   "metadata": {},
   "source": [
    "#### In this version, now there is one important concept added: \n",
    "There are different types of \"edges\" in traffic circumstances: \n",
    "\n",
    "    Free Flow: the traffic can move forward, this is a \"Downstream\" edge\n",
    "    \n",
    "    Congestion: there is a backward traffic shock wave. This is an \"Upstream\" edge. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9cc9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalGNN(nn.Module):\n",
    "    def __init__(self, node_features, periods):\n",
    "        super(TemporalGNN,self).__init__()\n",
    "        # Here we will use A3TGCN (mentioned above) as our temporal GNN layer\n",
    "\n",
    "        # DIFFERENT From before, now we will design two A3TGCN and combine them together. \n",
    "        self.tgnn_down = A3TGCN(in_channels=node_features,out_channels=32,periods=periods)\n",
    "        \n",
    "        self.tgnn_up = A3TGCN(in_channels=node_features,out_channels=32,periods=periods)\n",
    "\n",
    "        self.linear = nn.Linear(32, 12)\n",
    "\n",
    "    def forward(self,x,edge_index,edge_weight):\n",
    "        # Now before everything in this message passing & aggregation function\n",
    "        # we will classify nodes into \"upstream\" and \"downstream\"\n",
    "        # The default is \"upstream\"\n",
    "        edge_index_down = edge_index\n",
    "\n",
    "        # Now we will define the \"upstream\" -- Backward -- revserse\n",
    "        edge_index_up = torch.stack([edge_index[1],edge_index[0]],dim=0)\n",
    "\n",
    "        # Below will be the excution \n",
    "\n",
    "        h_down = self.tgnn_down(x,edge_index_down,edge_weight)\n",
    "\n",
    "        h_up = self.tgnn_up(x,edge_index_up,edge_weight)\n",
    "        # ReLU is the modeling phase transition in this traffic prediction context\n",
    "        # WHY? -- a linear model cannot learn from the rapid and sharp changes in traffic conditions\n",
    "        # ReLU introduces non-linearity, allowing the model to capture complex patterns and sudden shifts in traffic data\n",
    "\n",
    "        # simple sum aggregation of up and down\n",
    "        h = h_up + h_down \n",
    "        h = F.relu(h)\n",
    "\n",
    "        # Final prediction\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcab7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INstead of training overr and over again while the error is fluctuating but not decreasing.\n",
    "# the training should also learn how to stop\n",
    "\n",
    "class EarlyStopper:\n",
    "    # patience here means is the result is not improving \n",
    "    # __init__ is the fixed name of Constructor, which means initialization\n",
    "    # self literally means \"myself\"\n",
    "    # Also, here the min_delta means the expected minumum improvement, \n",
    "    # the drop of error must be bigger than this value, then the drop will be counted as a True\n",
    "    def __int__(self,patience=5,min_delta=0):\n",
    "    \n",
    "        self.patience = patience \n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        self.counter = 0\n",
    "\n",
    "        self.min_validation_loss = np.inf\n",
    "    \n",
    "    def early_stop(self,validation_loss):\n",
    "\n",
    "        # This is when the model made improvements\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self_counter = 0    # We dont count it as a step without improvemetens\n",
    "            return False\n",
    "        \n",
    "        # But when the model started to not make improvements\n",
    "        elif validation_loss > (self.min_valication_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5104651",
   "metadata": {},
   "source": [
    "#### After the model is initially configured, we will train it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b52d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the device for computation\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "PIN_MEMORY=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc1d0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can no longer simply use all the data to train\n",
    "# Here we will apply split\n",
    "full_data = list(dataset)\n",
    "\n",
    "# Split logic: 80% train, 20% validation\n",
    "\n",
    "split_index = int(len(full_data) * 0.8)\n",
    "train_dataset = full_data[:split_index]\n",
    "val_dataset = full_data[split_index:]\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=16,shuffle=True,\n",
    "                          pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=16,shuffle=True,\n",
    "                          pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad14c490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on 27399 samples, validating on 6850 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m optimizer.zero_grad()\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# This is how we get the prediction from the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m y_hat = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Here we calculate the loss between the prediction and the ground truth\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# INITIALLY TRIAL i use MSE, but soon i will use more feasible method here\u001b[39;00m\n\u001b[32m     26\u001b[39m loss = loss_fn(y_hat, batch.y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mTemporalGNN.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m     20\u001b[39m edge_index_up = torch.stack([edge_index[\u001b[32m1\u001b[39m],edge_index[\u001b[32m0\u001b[39m]],dim=\u001b[32m0\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Below will be the excution \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m h_down = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtgnn_down\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_index_down\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m h_up = \u001b[38;5;28mself\u001b[39m.tgnn_up(x,edge_index_up,edge_weight)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# ReLU is the modeling phase transition in this traffic prediction context\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# WHY? -- a linear model cannot learn from the rapid and sharp changes in traffic conditions\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# ReLU introduces non-linearity, allowing the model to capture complex patterns and sudden shifts in traffic data\u001b[39;00m\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# simple sum aggregation of up and down\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch_geometric_temporal/nn/recurrent/attentiontemporalgcn.py:76\u001b[39m, in \u001b[36mA3TGCN.forward\u001b[39m\u001b[34m(self, X, edge_index, edge_weight, H)\u001b[39m\n\u001b[32m     74\u001b[39m probs = torch.nn.functional.softmax(\u001b[38;5;28mself\u001b[39m._attention, dim=\u001b[32m0\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m period \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.periods):\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     H_accum = H_accum + probs[period] * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_base_tgcn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m H_accum\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch_geometric_temporal/nn/recurrent/temporalgcn.py:127\u001b[39m, in \u001b[36mTGCN.forward\u001b[39m\u001b[34m(self, X, edge_index, edge_weight, H)\u001b[39m\n\u001b[32m    125\u001b[39m H = \u001b[38;5;28mself\u001b[39m._set_hidden_state(X, H)\n\u001b[32m    126\u001b[39m Z = \u001b[38;5;28mself\u001b[39m._calculate_update_gate(X, edge_index, edge_weight, H)\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m R = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calculate_reset_gate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m H_tilde = \u001b[38;5;28mself\u001b[39m._calculate_candidate_state(X, edge_index, edge_weight, H, R)\n\u001b[32m    129\u001b[39m H = \u001b[38;5;28mself\u001b[39m._calculate_hidden_state(Z, H, H_tilde)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch_geometric_temporal/nn/recurrent/temporalgcn.py:89\u001b[39m, in \u001b[36mTGCN._calculate_reset_gate\u001b[39m\u001b[34m(self, X, edge_index, edge_weight, H)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_calculate_reset_gate\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, edge_index, edge_weight, H):\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     R = torch.cat([\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m, H], axis=\u001b[32m1\u001b[39m)\n\u001b[32m     90\u001b[39m     R = \u001b[38;5;28mself\u001b[39m.linear_r(R)\n\u001b[32m     91\u001b[39m     R = torch.sigmoid(R)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    239\u001b[39m cache = \u001b[38;5;28mself\u001b[39m._cached_edge_index\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     edge_index, edge_weight = \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached:\n\u001b[32m    245\u001b[39m         \u001b[38;5;28mself\u001b[39m._cached_edge_index = (edge_index, edge_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:99\u001b[39m, in \u001b[36mgcn_norm\u001b[39m\u001b[34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[39m\n\u001b[32m     96\u001b[39m num_nodes = maybe_num_nodes(edge_index, num_nodes)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     edge_index, edge_weight = \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     edge_weight = torch.ones((edge_index.size(\u001b[32m1\u001b[39m), ), dtype=dtype,\n\u001b[32m    104\u001b[39m                              device=edge_index.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch_geometric/utils/loop.py:652\u001b[39m, in \u001b[36madd_remaining_self_loops\u001b[39m\u001b[34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[39m\n\u001b[32m    648\u001b[39m     is_undirected = edge_index.is_undirected\n\u001b[32m    650\u001b[39m edge_index = edge_index[:, mask]\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_scripting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[32m    653\u001b[39m     edge_index._is_undirected = is_undirected\n\u001b[32m    655\u001b[39m edge_index = torch.cat([edge_index, loop_index], dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/my-pytorch-project/torch_env/lib/python3.11/site-packages/torch/_jit_internal.py:103\u001b[39m, in \u001b[36mis_scripting\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m7\u001b[39m):\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBroadcastingList\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = BroadcastingList1\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_scripting\u001b[39m() -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m    Function that returns True when in compilation and False otherwise. This\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m    is useful especially with the @unused decorator to leave code in your\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \u001b[33;03m                return unsupported_linear_op(x)\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "torch.mps.empty_cache()\n",
    "model = TemporalGNN(node_features=2,periods=12).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)    # Manually setup learning rate of Gradient Descent optimizer as 0.01\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "early_stopper = EarlyStopper()\n",
    "\n",
    "print(f'Starting training on {len(train_dataset)} samples, validating on {len(val_dataset)} samples...')\n",
    "\n",
    "\n",
    "for epoch in range(1,51):   # Train for 20 epochs\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    progressor = tqdm(train_loader,desc=f'Epoch {epoch:02d}',leave=False)\n",
    "    model.train()\n",
    "    for batch in progressor:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # This is how we get the prediction from the model\n",
    "\n",
    "        y_hat = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "\n",
    "        # Here we calculate the loss between the prediction and the ground truth\n",
    "        # INITIALLY TRIAL i use MSE, but soon i will use more feasible method here\n",
    "        loss = loss_fn(y_hat, batch.y)\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping to prevent exploding gradients\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        step += 1\n",
    "\n",
    "    avg_loss = epoch_loss / step\n",
    "\n",
    "    # Now below is the added evaluation part\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_step = 0\n",
    "    progressor2 = tqdm(val_loader,desc=f'Epoch {epoch:02d}',leave=False)\n",
    "    with torch.no_grad():   # We have to disable the gradient calculation\n",
    "        for batch in val_loader:\n",
    "\n",
    "            batch = batch.to(device)\n",
    "            y_hat = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            loss = loss_fn(y_hat,batch.y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_step += 1\n",
    "    \n",
    "    avg_val_loss = val_loss / val_step\n",
    "\n",
    "    print(f'Epoch {epoch:02d} | Train MAE: {avg_loss:.4f} | Val MAE: {avg_val_loss:.4f}')\n",
    "\n",
    "    if early_stopper.early_stop(avg_val_loss): \n",
    "        print(f'Early stopping is triggered.\\nThe training stops at Epoch {epoch}')\n",
    "        break\n",
    "\n",
    "\n",
    "print('Training process finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077972a",
   "metadata": {},
   "source": [
    "#### Here comes to my stage review?\n",
    "Where did we change? \n",
    "- The classification of adjacency matrix. We learnt how to deal with the heterogenous GNN, which in this circumstance indicate \"upstream\" and \"downstream\", two kinds of edge type.\n",
    "\n",
    "- The evaluation system. At the last raw edition, the error kept fluctuating and didnt see a decrease for a while. After studying, i learnt that the \"early stopping\" mechanism. So here we design the earlystop model and apply trian-validation split on the dataset. \n",
    "\n",
    "Why this matters? \n",
    "- In our traffic prediction, we are also trying to avoide overfitting -- when the training loss is decreasing but the validation loss is increasing. We have to tell the model, how to stop in time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
